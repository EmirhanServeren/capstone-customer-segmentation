{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUSTOMER SEGMENTATION"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, declaring necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import json     # for reading the key inside the json formatted file\n",
    "\n",
    "# for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyodbc   # for connecting database"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Connecting to Database\n",
    "\n",
    "Pyodbc library handles the connection between Jupyter notebook and MS SQL Server. SQL Server's key is hidden inside the json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('log.json')\n",
    "sql_key = json.load(f)     # returns JSON object as a dictionary\n",
    "\n",
    "cnxn = pyodbc.connect(sql_key['key'])     # establish a connection\n",
    "crsr = cnxn.cursor()                      # cursor enables to send command"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Sending Queries \n",
    "\n",
    "Queries are sent with respect to the decisions given on analytics phase. G and T type company data are retrieved separately."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For G (Şahıs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emirh\\AppData\\Local\\Temp\\ipykernel_2776\\1577447570.py:6: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  g_company_type_df = pd.read_sql(gk_query, cnxn)\n"
     ]
    }
   ],
   "source": [
    "gk_query= \"\"\"SELECT MUSTERI_ID, ID, CEK_NO, CEK_TUTAR, VADE_GUN, BK_LIMIT, BK_RISK,\n",
    "            BK_GECIKMEHESAP, BK_GECIKMEBAKIYE\n",
    "            FROM dbo.dataset\n",
    "            WHERE SIRKET_TURU LIKE 'G' \"\"\"\n",
    "\n",
    "g_company_type_df = pd.read_sql(gk_query, cnxn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MUSTERI_ID</th>\n",
       "      <th>ID</th>\n",
       "      <th>CEK_NO</th>\n",
       "      <th>CEK_TUTAR</th>\n",
       "      <th>VADE_GUN</th>\n",
       "      <th>BK_LIMIT</th>\n",
       "      <th>BK_RISK</th>\n",
       "      <th>BK_GECIKMEHESAP</th>\n",
       "      <th>BK_GECIKMEBAKIYE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11800527</td>\n",
       "      <td>2457932</td>\n",
       "      <td>70331933</td>\n",
       "      <td>20000</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12024009</td>\n",
       "      <td>2457933</td>\n",
       "      <td>3014103</td>\n",
       "      <td>25000</td>\n",
       "      <td>126</td>\n",
       "      <td>2213</td>\n",
       "      <td>226</td>\n",
       "      <td>2</td>\n",
       "      <td>1012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11800527</td>\n",
       "      <td>2457934</td>\n",
       "      <td>7031933</td>\n",
       "      <td>20000</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11724283</td>\n",
       "      <td>2457936</td>\n",
       "      <td>7198012</td>\n",
       "      <td>23000</td>\n",
       "      <td>151</td>\n",
       "      <td>52100</td>\n",
       "      <td>9481</td>\n",
       "      <td>3</td>\n",
       "      <td>3575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11879266</td>\n",
       "      <td>2457937</td>\n",
       "      <td>9090937</td>\n",
       "      <td>10000</td>\n",
       "      <td>151</td>\n",
       "      <td>280101</td>\n",
       "      <td>211301</td>\n",
       "      <td>3</td>\n",
       "      <td>4128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11879266</td>\n",
       "      <td>2457938</td>\n",
       "      <td>9090936</td>\n",
       "      <td>13458</td>\n",
       "      <td>121</td>\n",
       "      <td>280101</td>\n",
       "      <td>211301</td>\n",
       "      <td>3</td>\n",
       "      <td>4128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11854083</td>\n",
       "      <td>2457939</td>\n",
       "      <td>4535918</td>\n",
       "      <td>5200</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11654711</td>\n",
       "      <td>2457942</td>\n",
       "      <td>88624</td>\n",
       "      <td>110000</td>\n",
       "      <td>181</td>\n",
       "      <td>215261</td>\n",
       "      <td>150619</td>\n",
       "      <td>1</td>\n",
       "      <td>847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11723432</td>\n",
       "      <td>2457943</td>\n",
       "      <td>3331313</td>\n",
       "      <td>5300</td>\n",
       "      <td>121</td>\n",
       "      <td>104384</td>\n",
       "      <td>65599</td>\n",
       "      <td>3</td>\n",
       "      <td>2591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11577211</td>\n",
       "      <td>2457944</td>\n",
       "      <td>4602258</td>\n",
       "      <td>11000</td>\n",
       "      <td>187</td>\n",
       "      <td>215860</td>\n",
       "      <td>85589</td>\n",
       "      <td>4</td>\n",
       "      <td>6379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  MUSTERI_ID       ID    CEK_NO CEK_TUTAR VADE_GUN BK_LIMIT BK_RISK  \\\n",
       "0   11800527  2457932  70331933     20000      100        0       0   \n",
       "1   12024009  2457933   3014103     25000      126     2213     226   \n",
       "2   11800527  2457934   7031933     20000      100        0       0   \n",
       "3   11724283  2457936   7198012     23000      151    52100    9481   \n",
       "4   11879266  2457937   9090937     10000      151   280101  211301   \n",
       "5   11879266  2457938   9090936     13458      121   280101  211301   \n",
       "6   11854083  2457939   4535918      5200        4        0       0   \n",
       "7   11654711  2457942     88624    110000      181   215261  150619   \n",
       "8   11723432  2457943   3331313      5300      121   104384   65599   \n",
       "9   11577211  2457944   4602258     11000      187   215860   85589   \n",
       "\n",
       "  BK_GECIKMEHESAP BK_GECIKMEBAKIYE  \n",
       "0               0                0  \n",
       "1               2             1012  \n",
       "2               0                0  \n",
       "3               3             3575  \n",
       "4               3             4128  \n",
       "5               3             4128  \n",
       "6               0                0  \n",
       "7               1              847  \n",
       "8               3             2591  \n",
       "9               4             6379  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_company_type_df.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For T (Tüzel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emirh\\AppData\\Local\\Temp\\ipykernel_18068\\595317809.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  t_company_type_df = pd.read_sql(tk_query, cnxn)\n"
     ]
    }
   ],
   "source": [
    "tk_query= \"\"\"SELECT MUSTERI_ID, ID, CEK_NO, CEK_TUTAR, VADE_GUN, TK_NAKDILIMIT, TK_NAKDIRISK, TK_GAYRINAKDILIMIT, TK_GAYRINAKDIRISK, TK_GECIKMEHESAP, TK_GECIKMEBAKIYE FROM dbo.dataset WHERE SIRKET_TURU LIKE 'T' \"\"\"\n",
    "t_company_type_df = pd.read_sql(tk_query, cnxn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MACHINE LEARNING"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ML is going to be implemented to segment customer portfolio into clusters based on their risks. Firstly, the customer portfolio divided into two groups: T type and G type customers. Due to the differences between their attributes, this was inevitable step to be done. Also, it is crucial to define type of machine learning. Due to the attributes, it will be unsupervised learning. As observed, all attributes will be used are features. For providing accurate solution, we obtained that classification of the customer portfolio is a must requirements. In this sense, **K-means** is going to implemented.\n",
    "\n",
    "Next, the datasets will be prepared for the clustering. There is a need of deriving new attributes by using existing ones. Thus, the feature extraction must be done before putting data into model. In addition to this, data scaling is another significant task to complete. According to Dong, Zhang, and Chen (2020), *data scaling is a technique used in machine learning to adjust the range of features in a dataset, typically to a common scale between zero and one or -1 and 1.* The purpose of data scaling is to standardize the data, mitigate the impact of outliers, and ensure that all features are treated equally during model training. As stated in the paper, we are looking forward to handle large range of magnitudes with this method.\n",
    "\n",
    "Also, data will be divided into two as training and test for ML. Sarkar and Bali (2020) stated that training dataset is used to teach the algorithm to recognize patterns in the data, while the testing dataset is used to evaluate the algorithm's ability to generalize to new data. We are going to determine whether the model is good fit or not by using test dataset. It is a common fact that overfitting or underfitting models my occur during ML researches.\n",
    "\n",
    "Moreover, the optimal number of clusters are going to be obtained by using Elbow Method from the data. The elbow method is a critical technique for selecting the optimal number of clusters in k-means clustering, as it provides an objective way to determine the appropriate number of clusters and helps to prevent overfitting and improve the interpretability of the resulting clusters (Tang & Zhang, 2019). After this, we are going to train the model with the train dataset.\n",
    "\n",
    "After these steps, the accuracy of K-means model must be found out. Also, other appropriate unsupervised ML modelling techniques are going to be compared. The most fitting model's results are going to be saved into the database. The database is going to be integrated our data-oriented web application for strong Business Intelligence presentation.\n",
    "\n",
    "To conclude, our steps are;\n",
    "\n",
    "*   Feature Extraction\n",
    "*   Scaling Data\n",
    "*   Training/Test Set Division\n",
    "*   Elbow Method\n",
    "*   Accuracy Calculation\n",
    "*   Comparing K-means with Other Models\n",
    "*   Saving Results into Database\n",
    "*   Presenting Results via Streamlit Web-App"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Handle Data Types"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we have to assign data types before ML operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 229538 entries, 0 to 229537\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count   Dtype \n",
      "---  ------            --------------   ----- \n",
      " 0   MUSTERI_ID        229538 non-null  object\n",
      " 1   ID                229538 non-null  int64 \n",
      " 2   CEK_NO            229538 non-null  object\n",
      " 3   CEK_TUTAR         229538 non-null  object\n",
      " 4   VADE_GUN          229538 non-null  object\n",
      " 5   BK_LIMIT          229538 non-null  object\n",
      " 6   BK_RISK           229538 non-null  object\n",
      " 7   BK_GECIKMEHESAP   229538 non-null  object\n",
      " 8   BK_GECIKMEBAKIYE  229538 non-null  object\n",
      "dtypes: int64(1), object(8)\n",
      "memory usage: 15.8+ MB\n"
     ]
    }
   ],
   "source": [
    "g_company_type_df.info()    # to see the data types and missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emirh\\AppData\\Local\\Temp\\ipykernel_2776\\1768993693.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  g_company_type_df['MUSTERI_ID']=g_company_type_df['MUSTERI_ID'].str.replace(r'\\D', '').astype(int)\n"
     ]
    }
   ],
   "source": [
    "# there are several characters in the MUSTERI_ID column, so we need to remove them\n",
    "g_company_type_df['MUSTERI_ID']=g_company_type_df['MUSTERI_ID'].str.replace(r'\\D', '').astype(int)\n",
    "g_company_type_df['ID']=g_company_type_df['ID'].astype(int)\n",
    "\n",
    "# VADE_GUN represents the amount of day, so it is an integer\n",
    "g_company_type_df['VADE_GUN']=g_company_type_df['VADE_GUN'].astype(int)\n",
    "g_company_type_df['CEK_TUTAR']=g_company_type_df['CEK_TUTAR'].replace(',','.', regex=True).astype(float)\n",
    "\n",
    "# converting into float to use on ML model later\n",
    "g_company_type_df['BK_LIMIT']=g_company_type_df['BK_LIMIT'].astype(float)\n",
    "g_company_type_df['BK_RISK']=g_company_type_df['BK_RISK'].astype(float)\n",
    "g_company_type_df['BK_GECIKMEHESAP']=g_company_type_df['BK_GECIKMEHESAP'].astype(float)\n",
    "g_company_type_df['BK_GECIKMEBAKIYE']=g_company_type_df['BK_GECIKMEBAKIYE'].astype(float)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*CEK_NO* has several improper values, so we need to handle errors and convert it into integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used these queries to spot the non-integer values\n",
    "\"\"\"SELECT [CEK_NO]\n",
    "FROM [faktoring_db].[dbo].[dataset]\n",
    "WHERE CEK_NO like '%[^a-Z0-9]%'\n",
    "\n",
    "SELECT CEK_NO, COUNT(*) as count\n",
    "FROM [faktoring_db].[dbo].[dataset]\n",
    "WHERE CEK_NO like '%[^a-Z0-9]%'\n",
    "GROUP BY CEK_NO\n",
    "HAVING COUNT(*) > 0\n",
    "\n",
    "//OR USE THIS, MORE EFFICIENT RESULTS\n",
    "\n",
    "SELECT [ID],[CEK_NO]\n",
    "FROM [faktoring_db].[dbo].[dataset]\n",
    "WHERE ISNUMERIC([CEK_NO]) <> 1;\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solved the issue on MS SQL with the following script below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#...and solved the issue by using the following queries\n",
    "\"\"\"\n",
    "UPDATE [faktoring_db].[dbo].[dataset]\n",
    "SET [CEK_NO] = 1\n",
    "WHERE [ID] = 2770334;\n",
    "\n",
    "UPDATE [faktoring_db].[dbo].[dataset]\n",
    "SET [CEK_NO] = 2\n",
    "WHERE [ID] = 2494076;\n",
    "\n",
    "UPDATE [faktoring_db].[dbo].[dataset]\n",
    "SET [CEK_NO] = 3\n",
    "WHERE [ID] = 2501347;\n",
    "\n",
    "UPDATE [faktoring_db].[dbo].[dataset]\n",
    "SET [CEK_NO] = 4\n",
    "WHERE [ID] = 2551433;\n",
    "\n",
    "UPDATE [faktoring_db].[dbo].[dataset]\n",
    "SET [CEK_NO] = 5\n",
    "WHERE [ID] = 2551434;\n",
    "\n",
    "UPDATE [faktoring_db].[dbo].[dataset]\n",
    "SET [CEK_NO] = 6\n",
    "WHERE [ID] = 2633345;\n",
    "\n",
    "UPDATE [faktoring_db].[dbo].[dataset]\n",
    "SET [CEK_NO] = 7\n",
    "WHERE [ID] = 2689531;\n",
    "\n",
    "UPDATE [faktoring_db].[dbo].[dataset]\n",
    "SET [CEK_NO] = 8\n",
    "WHERE [ID] = 2699745;\n",
    "\n",
    "UPDATE [faktoring_db].[dbo].[dataset]\n",
    "SET [CEK_NO] = 9\n",
    "WHERE [ID] = 2703751;\n",
    "\n",
    "UPDATE [faktoring_db].[dbo].[dataset]\n",
    "SET [CEK_NO] = 10\n",
    "WHERE [ID] = 2715934;\n",
    "\n",
    "UPDATE [faktoring_db].[dbo].[dataset]\n",
    "SET [CEK_NO] = 11\n",
    "WHERE [ID] = 2828009;\n",
    "\n",
    "UPDATE [faktoring_db].[dbo].[dataset]\n",
    "SET [CEK_NO] = 12\n",
    "WHERE [ID] = 2828010;\n",
    "\n",
    "UPDATE [faktoring_db].[dbo].[dataset]\n",
    "SET [CEK_NO] = 13\n",
    "WHERE [ID] = 2828011;\n",
    "\n",
    "UPDATE [faktoring_db].[dbo].[dataset]\n",
    "SET [CEK_NO] = 14\n",
    "WHERE [ID] = 2828012;\n",
    "\n",
    "UPDATE [faktoring_db].[dbo].[dataset]\n",
    "SET [CEK_NO] = 15\n",
    "WHERE [ID] = 2828013;\n",
    "\n",
    "UPDATE [faktoring_db].[dbo].[dataset]\n",
    "SET [CEK_NO] = 16\n",
    "WHERE [ID] = 2516070 OR\n",
    "\t[ID] = 2525905 OR\n",
    "\t[ID] = 2573048 OR\n",
    "\t[ID] = 2685207 OR\n",
    "\t[ID] = 2727249;\n",
    "\n",
    "UPDATE [faktoring_db].[dbo].[dataset]\n",
    "SET [CEK_NO] = 17\n",
    "WHERE [ID] = 2741161;\n",
    "\n",
    "UPDATE [faktoring_db].[dbo].[dataset]\n",
    "SET [CEK_NO] = 18\n",
    "WHERE [ID] = 2766289;\n",
    "\n",
    "UPDATE [faktoring_db].[dbo].[dataset]\n",
    "SET [CEK_NO] = 19\n",
    "WHERE [ID] = 2809942;\n",
    "\n",
    "UPDATE [faktoring_db].[dbo].[dataset]\n",
    "SET [CEK_NO] = 20\n",
    "WHERE [ID] = 2815551;\n",
    "\n",
    "UPDATE [faktoring_db].[dbo].[dataset]\n",
    "SET [CEK_NO] = 21\n",
    "WHERE [ID] = 2850473;\n",
    "UPDATE [faktoring_db].[dbo].[dataset]\n",
    "SET [CEK_NO] = 22\n",
    "WHERE [ID] = 2911050;\n",
    "UPDATE [faktoring_db].[dbo].[dataset]\n",
    "SET [CEK_NO] = 23\n",
    "WHERE [ID] = 2912888;\n",
    "UPDATE [faktoring_db].[dbo].[dataset]\n",
    "SET [CEK_NO] = 24\n",
    "WHERE [ID] = 2912889;\n",
    "UPDATE [faktoring_db].[dbo].[dataset]\n",
    "SET [CEK_NO] = 25\n",
    "WHERE [ID] = 2922915;\n",
    "UPDATE [faktoring_db].[dbo].[dataset]\n",
    "SET [CEK_NO] = 26\n",
    "WHERE [ID] = 2922916;\n",
    "UPDATE [faktoring_db].[dbo].[dataset]\n",
    "SET [CEK_NO] = 27\n",
    "WHERE [ID] = 2923795;\n",
    "UPDATE [faktoring_db].[dbo].[dataset]\n",
    "SET [CEK_NO] = 28\n",
    "WHERE [ID] = 2703536;\n",
    "UPDATE [faktoring_db].[dbo].[dataset]\n",
    "SET [CEK_NO] = 29\n",
    "WHERE [ID] = 2740283;\n",
    "UPDATE [faktoring_db].[dbo].[dataset]\n",
    "SET [CEK_NO] = 30\n",
    "WHERE [ID] = 2622979;\n",
    "UPDATE [faktoring_db].[dbo].[dataset]\n",
    "SET [CEK_NO] = 31\n",
    "WHERE [ID] = 2740284;\n",
    "UPDATE [faktoring_db].[dbo].[dataset]\n",
    "SET [CEK_NO] = 32\n",
    "WHERE [ID] = 2740285;\n",
    "UPDATE [faktoring_db].[dbo].[dataset]\n",
    "SET [CEK_NO] = 33\n",
    "WHERE [ID] = 2740286;\n",
    "UPDATE [faktoring_db].[dbo].[dataset]\n",
    "SET [CEK_NO] = 34\n",
    "WHERE [ID] = 2740287;\n",
    "UPDATE [faktoring_db].[dbo].[dataset]\n",
    "SET [CEK_NO] = 35\n",
    "WHERE [ID] = 2740288;\n",
    "UPDATE [faktoring_db].[dbo].[dataset]\n",
    "SET [CEK_NO] = 36\n",
    "WHERE [ID] = 2740289;\n",
    "UPDATE [faktoring_db].[dbo].[dataset]\n",
    "SET [CEK_NO] = 37\n",
    "WHERE [ID] = 2740290;\n",
    "UPDATE [faktoring_db].[dbo].[dataset]\n",
    "SET [CEK_NO] = 38\n",
    "WHERE [ID] = 2780745;\n",
    "UPDATE [faktoring_db].[dbo].[dataset]\n",
    "SET [CEK_NO] = 39\n",
    "WHERE [ID] = 2782835;\n",
    "UPDATE [faktoring_db].[dbo].[dataset]\n",
    "SET [CEK_NO] = 40\n",
    "WHERE [ID] = 2782836;\n",
    "UPDATE [faktoring_db].[dbo].[dataset]\n",
    "SET [CEK_NO] = 41\n",
    "WHERE [ID] = 2823409;\n",
    "UPDATE [faktoring_db].[dbo].[dataset]\n",
    "SET [CEK_NO] = 42\n",
    "WHERE [ID] = 2823497;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, the script is executed successfully\n",
    "g_company_type_df['CEK_NO']=g_company_type_df['CEK_NO'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking uniqueness of ID\n",
    "g_company_type_df['ID'].is_unique   # check if there is any duplicate in ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 229538 entries, 0 to 229537\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   MUSTERI_ID        229538 non-null  int32  \n",
      " 1   ID                229538 non-null  int32  \n",
      " 2   CEK_NO            229538 non-null  int64  \n",
      " 3   CEK_TUTAR         229538 non-null  float64\n",
      " 4   VADE_GUN          229538 non-null  int32  \n",
      " 5   BK_LIMIT          229538 non-null  float64\n",
      " 6   BK_RISK           229538 non-null  float64\n",
      " 7   BK_GECIKMEHESAP   229538 non-null  float64\n",
      " 8   BK_GECIKMEBAKIYE  229538 non-null  float64\n",
      "dtypes: float64(5), int32(3), int64(1)\n",
      "memory usage: 13.1 MB\n"
     ]
    }
   ],
   "source": [
    "g_company_type_df.info()    # to see the data types after the changes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Feature Extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must create a new attribute called **BK_ORAN** which is *derived by diving BK_RISK to BK_LIMIT*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this when BK_LIMIT is not 0:\n",
    "# g_company_type_df['BK_ORAN']=g_company_type_df['BK_RISK']/g_company_type_df['BK_LIMIT']\n",
    "# else handle division error"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Scaling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_scaler(df):\n",
    "    scaler.fit(df)      # df is not exist yet, volatile to change later\n",
    "    return scaler.transform(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Elbow Method\n",
    "\n",
    "We aim to maximize the efficiency of segmentation while minimizing the number of clusters. In this sense, Elbow Method is crucial concept to satisfy this requirement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing scikit-learning library for the K-means model\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_clusters(df, maximum_K):\n",
    "    clusters_centers = []   # appending inertia value coming from the model\n",
    "    k_values = []           # putting k values from 0 to maximum K\n",
    "\n",
    "    for k in range(1, maximum_K):\n",
    "        kmeans_model = KMeans(n_clusters = k)\n",
    "        kmeans_model.fit(df)\n",
    "\n",
    "        clusters_centers.append(kmeans_model.inertia_)\n",
    "        k_values.append(k)\n",
    "\n",
    "    return clusters_centers, k_values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note About **Inertia**:\n",
    "\n",
    "Inertia measures how well a dataset was clustered by K-Means. It is calculated by measuring the distance between each data point and its centroid, squaring this distance, and summing these squares across one cluster. A good model is one with low inertia AND a low number of clusters (K) *-Codeacademy*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step, illustrating an elbow method for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_elbow_plot(clusters_centers, k_values):\n",
    "    figure = plt.subplots(figsize = (12, 6))\n",
    "    plt.plot(k_values, clusters_centers, 'o-', color = 'blue')\n",
    "    plt.xlabel(\"Number of Clusters\")\n",
    "    plt.ylabel(\"Cluster Inertia\")\n",
    "    plt.title(\"Elbow Plot of Model\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_centers, k_values = find_optimal_clusters(df, 16)\n",
    "generate_elbow_plot(clusters_centers, k_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
